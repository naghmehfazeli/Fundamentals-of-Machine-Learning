{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7bb1ff003f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarkerCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfolium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPopup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium import IFrame,Popup\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import pysal as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/gross_rent_with_population.csv\").sort_values(['Zip_Code', 'Samples'], ascending=False)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_series = gpd.GeoSeries(data.apply(lambda z: Point(z['Lon'], z['Lat']) , 1), crs={'init': 'epsg:4326'})\n",
    "\n",
    "geo_data = gpd.GeoDataFrame(data.drop(columns=['Lon', 'Lat']), geometry=geo_series).reset_index(drop=True)\n",
    "geo_data.info()\n",
    "geo_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine data with the same place name\n",
    "tmp = geo_data.reset_index(drop=True)\n",
    "tmp = tmp.drop(columns=[\"Zip_Code\", \"ALand\", \"AWater\", \"Median\", \"Stdev\"])\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pre-aggregate data on city level\n",
    "tmp['totals'] = tmp['Mean'] * tmp['Samples']\n",
    "citywise_data = tmp.dissolve(by=['State_Name','County', 'City'], aggfunc='sum', as_index=False)\n",
    "citywise_data['Mean'] = (citywise_data.totals / citywise_data.Samples).fillna(0)\n",
    "citywise_data.geometry = citywise_data.geometry.centroid\n",
    "citywise_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read counties\n",
    "counties = gpd.read_file(\"data/gz_2010_us_050_00_20m/gz_2010_us_050_00_20m.shp\").set_index('GEO_ID', drop=False)\n",
    "join_result = gpd.tools.sjoin(counties, citywise_data.to_crs(counties.crs), op='contains').reset_index()\n",
    "join_result.head()\n",
    "join_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiply mean and Samples to be able to calculate the mean by county\n",
    "sum_columns = join_result.groupby('GEO_ID').sum()\n",
    "counties['Mean'] = (sum_columns['totals'] / sum_columns['Samples']).fillna(0)\n",
    "counties['Population'] = (sum_columns['Population']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counties['Population'] = counties['Population'].fillna(0).astype(np.int64)\n",
    "counties['Mean'] = counties['Mean'].fillna(0).astype(np.int64)\n",
    "counties.info()\n",
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_choropleth(mapobj, gdf, id_field, value_field, legend_name, fill_color = 'YlOrRd', fill_opacity = 0.6, \n",
    "                    line_opacity = 0.2, num_classes = 5, classifier = 'Fisher_Jenks'):\n",
    "    #Allow for 3 Pysal map classifiers to display data\n",
    "    #Generate list of breakpoints using specified classification scheme. List of breakpoint will be input to choropleth function\n",
    "    if classifier == 'Fisher_Jenks':\n",
    "        threshold_scale=ps.esda.mapclassify.Fisher_Jenks(gdf[value_field], k = num_classes).bins.tolist()\n",
    "    if classifier == 'Equal_Interval':\n",
    "        threshold_scale=ps.esda.mapclassify.Equal_Interval(gdf[value_field], k = num_classes).bins.tolist()\n",
    "    if classifier == 'Quantiles':\n",
    "        threshold_scale=ps.esda.mapclassify.Quantiles(gdf[value_field], k = num_classes).bins.tolist()\n",
    "    if classifier == 'Percentiles':\n",
    "        num_classes = 6\n",
    "        threshold_scale=ps.esda.mapclassify.Percentiles(gdf[value_field], pct=[10, 50, 90, 99, 99.9, 100]).bins.tolist()\n",
    "    if classifier == 'Jenks_Caspall':\n",
    "        threshold_scale=ps.esda.mapclassify.Jenks_Caspall(gdf[value_field],  k = num_classes).bins.tolist()\n",
    "    \n",
    "    #Convert the GeoDataFrame to WGS84 coordinate reference system\n",
    "    gdf_wgs84 = gdf.to_crs({'init': 'epsg:4326'})\n",
    "    \n",
    "    #Call Folium choropleth function, specifying the geometry as a the WGS84 dataframe converted to GeoJSON, the data as \n",
    "    #the GeoDataFrame, the columns as the user-specified id field and and value field.\n",
    "    #key_on field refers to the id field within the GeoJSON string\n",
    "    mapobj.choropleth(gdf_wgs84.to_json(), data = gdf,\n",
    "                columns = [id_field, value_field], key_on = 'feature.properties.{}'.format(id_field),\n",
    "                fill_color = fill_color, fill_opacity = fill_opacity, line_opacity = line_opacity,  \n",
    "                threshold_scale = threshold_scale, legend_name = legend_name, highlight=False, smooth_factor=1.0)\n",
    "    return mapobj\n",
    "\n",
    "def add_point_clusters(mapobj, gdf, popup_field_list, layer_name):\n",
    "    #Create empty lists to contain the point coordinates and the point pop-up information\n",
    "    coords, popups = [], [] \n",
    "    #Loop through each record in the GeoDataFrame\n",
    "    for i, row in gdf.iterrows():\n",
    "        #Append lat and long coordinates to \"coords\" list\n",
    "        coords.append([row.geometry.y, row.geometry.x])\n",
    "        #Join together the fields in \"popup_field_list\" with a linebreak between them\n",
    "        label = '<br>'.join([\"{name}: {value}\".format(name=field, value=str(row[field]) if type(row[field]) is str or type(row[field]) is int else \"{:.1f}\".format(row[field])) for field in popup_field_list])\n",
    "        #Append an IFrame that uses the HTML string to the \"popups\" list \n",
    "        popups.append(Popup(label))\n",
    "        \n",
    "    #Create a Folium feature group for this layer, since we will be displaying multiple layers\n",
    "    pt_lyr = folium.FeatureGroup(name = layer_name)\n",
    "    \n",
    "    #Add the clustered points of crime locations and popups to this layer\n",
    "    pt_lyr.add_child(MarkerCluster(locations = coords, popups = popups))\n",
    "    \n",
    "    #Add this point layer to the map object\n",
    "    mapobj.add_child(pt_lyr)\n",
    "    return mapobj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = folium.Map(location=[48, -102], zoom_start=3, control_scale=True, prefer_canvas=True)\n",
    "\n",
    "m = add_choropleth(m, counties, 'GEO_ID', 'Mean', legend_name='Mean Gross Rent', classifier='Percentiles', num_classes=6)\n",
    "m = add_point_clusters(m, citywise_data, ['City','Population','Mean'], 'Mean Gross Rent per City')\n",
    "folium.LayerControl().add_to(m) #Add layer control to toggle on/off\n",
    "m.save(\"data/test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
